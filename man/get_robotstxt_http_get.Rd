% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/get_robotstxt_http_get.R
\name{get_robotstxt_http_get}
\alias{get_robotstxt_http_get}
\title{get_robotstxt() worker function to execute HTTP request}
\usage{
get_robotstxt_http_get(domain,
  user_agent = utils::sessionInfo()$R.version$version.string,
  ssl_verifypeer = 1)
}
\arguments{
\item{domain}{the domain to get tobots.txt. file for}

\item{user_agent}{the user agent to use for HTTP request header}

\item{ssl_verifypeer}{analog to CURL option
\url{https://curl.haxx.se/libcurl/c/CURLOPT_SSL_VERIFYPEER.html}
-- and might help with robots.txt file retrieval in some cases}
}
\description{
get_robotstxt() worker function to execute HTTP request
}
