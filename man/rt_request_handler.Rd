% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/rt_request_handler.R
\name{rt_request_handler}
\alias{rt_request_handler}
\title{rt_request_handler}
\usage{
rt_request_handler(request, on_server_error = c("disallow", "error",
  "do_not_cache"), on_client_error = c("allow", "warn", "cache"),
  on_not_found = c("allow", "warn", "cache"), on_redirect = c("ignore",
  "message", "cache"), on_domain_change = c("allow", "warn", "cache"),
  on_file_type_mismatch = c("allow", "warn", "cache"),
  on_suspect_content = c("allow", "warn", "cache"), warn = TRUE,
  encoding = "UTF-8")
}
\arguments{
\item{request}{result of an HTTP request (e.g. httr::GET())}

\item{on_server_error}{request state handler for any 5xx status}

\item{on_client_error}{request state handler for any 4xx HTTP status that is
not 404}

\item{on_not_found}{request state handler for HTTP status 404}

\item{on_redirect}{request state handler for any 3xx HTTP status}

\item{on_domain_change}{request state handler for any 3xx HTTP status where
domain did change as well}

\item{on_file_type_mismatch}{request state handler for content type other
than 'text/plain'}

\item{on_suspect_content}{request state handler for content that seems to be
something else than a robots.txt file (usually a JSON, XML or HTML)}
}
\value{
a list with three items following the following schema: \cr \code{
  list( rtxt = "", problems = list( "redirect" = list( status_code = 301 ),
  "domain" = list(from_url = "...", to_url = "...") ) ) }
}
\description{
A helper function for get_robotstxt() that will extract the robots.txt file
from the HTTP request result object. furthermore it will inform
get_robotstxt() if the request should be cached and which problems occured.
}
